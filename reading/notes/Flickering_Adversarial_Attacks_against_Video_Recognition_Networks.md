
**Title:** Flickering_Adversarial_Attacks_against_Video_Recognition_Networks

**Source:** --

**Authors:** Roi Pony, Itay Naeh, Shie Mannor

---

**Summary**  

This work present a manipulation scheme for fooling video classifiers. 
- Introduce a flickering temporal perturbation.
- Unnoticeable by human observers.
- Implementable in the real world.


---

**Strengthens**  

- The relative unperceptability to the human observer  
- Achieved by small and smooth perturbations 
- The flickering perturbation can be implemented in real world scenarios since it does not require a complex spatial adversarial pattern to be projected upon the scene
- We present a time-invariant adversarial attack that can be applied to the recorded scene without assuming that the perturbation of each frame is applied at the right time

---

**Weaknesses**  

- It is difficult to achieve in the physical world, and changing the RGB channel will affect the video effect

---

**Adversarial Video Examples**

We encourage the readers to view the adversarial videos in the following:

https://bit.ly/Flickering_Attack_videos

https://bit.ly/Over_the_Air_videos

https://bit.ly/Over_the_Air_scene_based_videos

---
**Application scenario**

- Add adjustable filters on the camera to achieve the effect of changing the RGB of the scene


